{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import exiftool\n",
    "import glob\n",
    "import re\n",
    "import base64\n",
    "import sqlalchemy\n",
    "from sqlalchemy.dialects import postgresql\n",
    "from ast import literal_eval\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://%(PGUSER)s:%(PGPASSWORD)s@localhost:5432/work' % os.environ)\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_rows', 2000)\n",
    "pd.set_option('display.max_columns', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import from CSVs to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# various columns that might be comments/descriptions/etc for the files\n",
    "COMMENT_COLS = {\n",
    "    \"XMP:UserComment\", \"QuickTime:Description\", \"IPTC:Caption-Abstract\",\n",
    "    \"File:Comment\", \"XMP:Description\", \"EXIF:ImageDescription\", \"EXIF:UserComment\", \"EXIF:XPComment\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read metadata files creating from local_photos.py process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"data/image-metadata-*\")\n",
    "dfs = []\n",
    "for f in files:\n",
    "    dfs.append(pd.read_csv(f, low_memory=False))\n",
    "df_raw = pd.concat(dfs, ignore_index=True, sort=False)\n",
    "df_raw_summary = df_raw.notnull().sum()\n",
    "keep_cols = []\n",
    "str_vals = []\n",
    "row_count = df_raw.shape[0]\n",
    "for k, v in df_summary.iteritems():\n",
    "    cnt = float(v)\n",
    "    # 10% of files and not a warning or description fields or date/size/w/h\n",
    "    if (cnt/row_count > 0.1 and not re.match(r'(warning|unname)', k.lower())) \\\n",
    "            or (k in COMMENT_COLS) \\\n",
    "            or re.match(r'(date|width|height|size)', k.lower()):\n",
    "        keep_cols.append(k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data frame suitable for import into a database and filtered to select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_import = df_raw[keep_cols].copy()\n",
    "df_import.columns = df_import.columns.str.lower()\n",
    "df_import.columns = df_import.columns.str.replace('[^a-z0-9]+', '_', regex=True)\n",
    "df_import = df_import[sorted(df_import.columns)].copy()\n",
    "df_import['file_path'] = df_import['file_directory'] + '/' + df_import['file_filename']\n",
    "df_import = df_import.replace(to_replace= r'\\\\', value= '', regex=True)\n",
    "dtypes = {}\n",
    "for col in df_import.columns:\n",
    "    if re.match(r'thumb.*[0-9]', col):\n",
    "        df_import[col] = df_import[col].apply(literal_eval)\n",
    "        dtypes[col] = postgresql.ARRAY(sqlalchemy.types.SMALLINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a small version of the postgres table in a database. We will subsequently use a csv and bulk `COPY` for better speed and debugability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_import.head(10).to_sql('photo_file_new', con=engine, method=\"multi\", if_exists=\"fail\", index=False, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create copy of the postgres-typed dataframe so that we can export to a csv that is readyfor a bulk copy to postgres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat data for csv loading\n",
    "df_export = df_import.copy()\n",
    "for col in df_export.columns:\n",
    "    if re.match(r'thumb.*[0-9]', col):\n",
    "        df_export[col] = '{' + df_export[col].apply(lambda d: ','.join([str(dd) for dd in d])) + '}'\n",
    "        df_export[col] = df_export[col].astype(str)\n",
    "df_export.to_csv(\"photo_file_new.txt\", sep='\\t', header=False, na_rep='', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import into postgres by running this command on the command line outside of notebook.\n",
    "\n",
    "`cat photo_file_new.txt | psql -U postgres -d work -c \"COPY photo_file_new from STDIN WITH NULL ''\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring Google Photos Metadata into Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_goog = pd.read_json(\"google-photos.jsonline\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_goog['creation_time'] = pd.to_datetime(df_goog[\"mediaMetadata\"].apply(lambda x: x['creationTime']))\n",
    "df_goog['width'] = df_goog[\"mediaMetadata\"].apply(lambda x: int(x['width']))\n",
    "df_goog['height'] = df_goog[\"mediaMetadata\"].apply(lambda x: int(x['height']))\n",
    "df_goog['camera_make'] = df_goog[\"mediaMetadata\"].apply(lambda x: x.get(\"photo\", {}).get('cameraMake'))\n",
    "df_goog['camera_model'] = df_goog[\"mediaMetadata\"].apply(lambda x: x.get(\"photo\", {}).get('cameraModel'))\n",
    "df_goog.drop(\"mediaMetadata\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_goog.to_sql('photo_google', con=engine, method=\"multi\", if_exists=\"fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup, analysis, research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# looking for latitude\n",
    "list(filter(lambda d: 'long' in d.lower(), df_final.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at one row of data\n",
    "df_import.iloc[[10589]].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = base64.b64decode(df['thumb_color'][1])\n",
    "fw = open(\"img_color.jpg\", \"wb\")\n",
    "fw.write(img)\n",
    "fw.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tommy)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
