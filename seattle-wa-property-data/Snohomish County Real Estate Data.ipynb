{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_utils\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_utils.download_and_unzip_file(\"ftp://ftp.snoco.org/Assessor/shapefiles/parcels.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shp2pgsql -s 2285 -W latin1 -D data/parcels.shp import.snohomish_county_parcel_geo > data/snohomish_county_parcel_geo.sql\n",
    "!psql -U postgres -d work -f data/snohomish_county_parcel_geo.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql -U postgres -d work --tuples-only -c \"select 'DROP TYPE IF EXISTS snohomish_county_use_type;  CREATE TYPE snohomish_county_use_type AS ENUM (' || array_to_string(array_agg(quote_literal(dd) ORDER BY dd), ', ') || ');' from (select distinct usecode dd from import.snohomish_county_parcel_geo) t\" > sql/create_snohomish_county_enums.sql\n",
    "!psql -U postgres -d work -f sql/create_snohomish_county_enums.sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_utils.run_clean_script(\"snohomish_county_parcel_geo\")\n",
    "import_utils.run_sql(\"DROP TABLE import.snohomish_county_parcel_geo\")\n",
    "import_utils.run_command(\"rm data/parcels.*\")\n",
    "import_utils.run_command(\"rm data/disclaimer_termsofuse.txt\")\n",
    "import_utils.run_command(\"rm data/taxacct_document.dbf\")\n",
    "import_utils.run_command(\"rm data/parcels_data_dictionary.pdf\")\n",
    "import_utils.run_command(\"rm data/snohomish_county_parcel_geo.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O data/sno-2016.xlsx ftp://ftp.snoco.org/Assessor/Property_Sales/Snohomish%20County%20Sales/2016.07.21_Entire%20County.xlsx\n",
    "!wget -O data/sno-2017.xlsx ftp://ftp.snoco.org/Assessor/Property_Sales/Snohomish%20County%20Sales/2017.02.01_Entire%20County.xlsx\n",
    "!wget -O data/sno-2018.xlsx ftp://ftp.snoco.org/Assessor/Property_Sales/Snohomish%20County%20Sales/2018.03.20_Entire%20County.xlsx\n",
    "!wget -O data/sno-2018_2.xlsx ftp://ftp.snoco.org/Assessor/Property_Sales/Snohomish%20County%20Sales/2018.10.24_Entire%20County.xlsx\n",
    "!wget -O data/sno-2019.xlsx ftp://ftp.snoco.org/Assessor/Property_Sales/Snohomish%20County%20Sales/2019.05.21_Entire%20County.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-14 18:07:39: start load_csv_to_postgres snohomish_sale_2016\n",
      "2019-09-14 18:07:39: create table: import.snohomish_sale_2016\n",
      "2019-09-14 18:07:39: running sql\n",
      "2019-09-14 18:07:39: b'NOTICE:  table \"snohomish_sale_2016\" does not exist, skipping\\nCREATE TABLE\\n'\n",
      "2019-09-14 18:07:39: done running sql\n",
      "2019-09-14 18:07:39: load data\n",
      "2019-09-14 18:07:40: b'COPY 85214\\n'\n",
      "2019-09-14 18:07:40: trim data\n",
      "2019-09-14 18:07:40: running sql\n",
      "2019-09-14 18:07:42: b'UPDATE 85214\\n'\n",
      "2019-09-14 18:07:42: done running sql\n",
      "2019-09-14 18:07:42: empty to null\n",
      "2019-09-14 18:07:42: running sql\n",
      "2019-09-14 18:07:43: b'UPDATE 85214\\n'\n",
      "2019-09-14 18:07:43: done running sql\n",
      "2019-09-14 18:07:43: done load_csv_to_postgres import.snohomish_sale_2016\n",
      "2019-09-14 18:08:59: start load_csv_to_postgres snohomish_sale_2017\n",
      "2019-09-14 18:08:59: create table: import.snohomish_sale_2017\n",
      "2019-09-14 18:08:59: running sql\n",
      "2019-09-14 18:08:59: b'NOTICE:  table \"snohomish_sale_2017\" does not exist, skipping\\nCREATE TABLE\\n'\n",
      "2019-09-14 18:08:59: done running sql\n",
      "2019-09-14 18:08:59: load data\n",
      "2019-09-14 18:09:00: b'COPY 96061\\n'\n",
      "2019-09-14 18:09:00: trim data\n",
      "2019-09-14 18:09:00: running sql\n",
      "2019-09-14 18:09:02: b'UPDATE 96061\\n'\n",
      "2019-09-14 18:09:02: done running sql\n",
      "2019-09-14 18:09:02: empty to null\n",
      "2019-09-14 18:09:02: running sql\n",
      "2019-09-14 18:09:03: b'UPDATE 96061\\n'\n",
      "2019-09-14 18:09:03: done running sql\n",
      "2019-09-14 18:09:03: done load_csv_to_postgres import.snohomish_sale_2017\n",
      "2019-09-14 18:10:12: start load_csv_to_postgres snohomish_sale_2018\n",
      "2019-09-14 18:10:12: create table: import.snohomish_sale_2018\n",
      "2019-09-14 18:10:12: running sql\n",
      "2019-09-14 18:10:12: b'NOTICE:  table \"snohomish_sale_2018\" does not exist, skipping\\nCREATE TABLE\\n'\n",
      "2019-09-14 18:10:12: done running sql\n",
      "2019-09-14 18:10:12: load data\n",
      "2019-09-14 18:10:13: b'COPY 87076\\n'\n",
      "2019-09-14 18:10:13: trim data\n",
      "2019-09-14 18:10:13: running sql\n",
      "2019-09-14 18:10:15: b'UPDATE 87076\\n'\n",
      "2019-09-14 18:10:15: done running sql\n",
      "2019-09-14 18:10:15: empty to null\n",
      "2019-09-14 18:10:15: running sql\n",
      "2019-09-14 18:10:16: b'UPDATE 87076\\n'\n",
      "2019-09-14 18:10:16: done running sql\n",
      "2019-09-14 18:10:16: done load_csv_to_postgres import.snohomish_sale_2018\n",
      "2019-09-14 18:11:22: start load_csv_to_postgres snohomish_sale_2018_2\n",
      "2019-09-14 18:11:22: create table: import.snohomish_sale_2018_2\n",
      "2019-09-14 18:11:22: running sql\n",
      "2019-09-14 18:11:22: b'NOTICE:  table \"snohomish_sale_2018_2\" does not exist, skipping\\nCREATE TABLE\\n'\n",
      "2019-09-14 18:11:22: done running sql\n",
      "2019-09-14 18:11:22: load data\n",
      "2019-09-14 18:11:23: b'COPY 81931\\n'\n",
      "2019-09-14 18:11:23: trim data\n",
      "2019-09-14 18:11:23: running sql\n",
      "2019-09-14 18:11:25: b'UPDATE 81931\\n'\n",
      "2019-09-14 18:11:25: done running sql\n",
      "2019-09-14 18:11:25: empty to null\n",
      "2019-09-14 18:11:25: running sql\n",
      "2019-09-14 18:11:26: b'UPDATE 81931\\n'\n",
      "2019-09-14 18:11:26: done running sql\n",
      "2019-09-14 18:11:26: done load_csv_to_postgres import.snohomish_sale_2018_2\n",
      "2019-09-14 18:12:28: start load_csv_to_postgres snohomish_sale_2019\n",
      "2019-09-14 18:12:28: create table: import.snohomish_sale_2019\n",
      "2019-09-14 18:12:28: running sql\n",
      "2019-09-14 18:12:28: b'NOTICE:  table \"snohomish_sale_2019\" does not exist, skipping\\nCREATE TABLE\\n'\n",
      "2019-09-14 18:12:28: done running sql\n",
      "2019-09-14 18:12:28: load data\n",
      "2019-09-14 18:12:29: b'COPY 78868\\n'\n",
      "2019-09-14 18:12:29: trim data\n",
      "2019-09-14 18:12:29: running sql\n",
      "2019-09-14 18:12:31: b'UPDATE 78868\\n'\n",
      "2019-09-14 18:12:31: done running sql\n",
      "2019-09-14 18:12:31: empty to null\n",
      "2019-09-14 18:12:31: running sql\n",
      "2019-09-14 18:12:32: b'UPDATE 78868\\n'\n",
      "2019-09-14 18:12:32: done running sql\n",
      "2019-09-14 18:12:32: done load_csv_to_postgres import.snohomish_sale_2019\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_excel(\"data/sno-2016.xlsx\")\n",
    "df.to_csv(\"data/sno-import.csv\", index=False)\n",
    "import_utils.load_csv_to_postgres(\"snohomish_sale_2016\", \"data/sno-import.csv\")\n",
    "\n",
    "df = pandas.read_excel(\"data/sno-2017.xlsx\")\n",
    "df.to_csv(\"data/sno-import.csv\", index=False)\n",
    "import_utils.load_csv_to_postgres(\"snohomish_sale_2017\", \"data/sno-import.csv\")\n",
    "\n",
    "df = pandas.read_excel(\"data/sno-2018.xlsx\")\n",
    "df.to_csv(\"data/sno-import.csv\", index=False)\n",
    "import_utils.load_csv_to_postgres(\"snohomish_sale_2018\", \"data/sno-import.csv\")\n",
    "\n",
    "df = pandas.read_excel(\"data/sno-2018_2.xlsx\")\n",
    "df.to_csv(\"data/sno-import.csv\", index=False)\n",
    "import_utils.load_csv_to_postgres(\"snohomish_sale_2018_2\", \"data/sno-import.csv\")\n",
    "\n",
    "df = pandas.read_excel(\"data/sno-2019.xlsx\")\n",
    "df.to_csv(\"data/sno-import.csv\", index=False)\n",
    "import_utils.load_csv_to_postgres(\"snohomish_sale_2019\", \"data/sno-import.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
