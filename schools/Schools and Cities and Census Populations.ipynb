{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7809909c-3953-4671-a97a-45da8a008e81",
   "metadata": {},
   "source": [
    "## Public and private school data\n",
    "\n",
    "- public schools: https://hifld-geoplatform.opendata.arcgis.com/datasets/public-schools/explore\n",
    "- private schools: https://hifld-geoplatform.opendata.arcgis.com/datasets/private-schools/explore\n",
    "\n",
    "### Census data\n",
    "\n",
    "Income, population, education, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd660ff-0646-4d9d-99fd-901e55337f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import requests\n",
    "import shutil\n",
    "import subprocess\n",
    "import psycopg2\n",
    "from psycopg2.extras import DictCursor\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "CENSUS_API_KEY = '5fdf56abf43997adf0d8533a71dea339e4ac5974'\n",
    "BASE_URL = 'https://api.census.gov/data'\n",
    "CONN_STR = \"postgresql://tommyunger@localhost/work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcccfd6-cf21-4986-a903-43a023b52f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_details(data_set, variable):\n",
    "    ENDPOINT = f\"{BASE_URL}/{data_set}/variables/{variable}.json\"\n",
    "    response = requests.get(ENDPOINT)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_or_insert_metric(data_set, census_id):\n",
    "    check_sql = \"\"\"SELECT metric_id FROM census.metric WHERE census_id = %s\"\"\"\n",
    "    insert_sql = \"\"\"\n",
    "        INSERT INTO census.metric (data_set, census_id, name, details) \n",
    "        VALUES (%s, %s, %s, %s)\n",
    "        RETURNING metric_id;\n",
    "    \"\"\"\n",
    "    with psycopg2.connect(CONN_STR) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(check_sql, (census_id,))\n",
    "            result = cursor.fetchone()\n",
    "            if result:\n",
    "                return result[0]\n",
    "            else:\n",
    "                dets = get_metric_details(data_set, census_id)\n",
    "                name = re.sub(r\"[^a-z0-9]+\", \" \", (dets['concept'] + ' ' + dets['label']).lower()).strip()\n",
    "                details = str(dets)\n",
    "                cursor.execute(insert_sql, (data_set, census_id, name, details))\n",
    "                new_metric_id = cursor.fetchone()[0]\n",
    "                return new_metric_id\n",
    "\n",
    "def get_states():\n",
    "    sql = f\"\"\"select statefp, stusps, name\n",
    "            from census.geo_state\n",
    "            order by 1\"\"\"\n",
    "    with psycopg2.connect(CONN_STR) as conn:\n",
    "        with conn.cursor(cursor_factory=DictCursor) as cursor:\n",
    "            cursor.execute(sql)\n",
    "            results = cursor.fetchall()\n",
    "            return [dict(row) for row in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c0347-e3ac-4755-a01e-ec69eba44f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "    filename = re.sub(r\"[^a-z0-9]+\", \"_\", url.lower()) + \".zip\"\n",
    "    filename = os.path.join(dest_folder, filename)\n",
    "    if os.path.exists(filename):\n",
    "        return filename\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    return filename\n",
    "\n",
    "def unzip_file(file_path, dest_folder):\n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dest_folder)\n",
    "    return dest_folder\n",
    "\n",
    "def table_exists(table_name, schema_name='public'):\n",
    "    connection = psycopg2.connect(\"postgresql://localhost/work\")\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(f\"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_schema='{schema_name}' and table_name='{table_name}');\")\n",
    "    exists = cursor.fetchone()[0]\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    return exists\n",
    "\n",
    "def shp2pgsql(schema_name, table_name, shp_folder, srid):\n",
    "    # Assuming only one shapefile in the directory. Modify as needed.\n",
    "    shp_file = next((f for f in os.listdir(shp_folder) if f.endswith('.shp')), None)\n",
    "    if shp_file is None:\n",
    "        raise ValueError('No shapefile found in the directory.')\n",
    "    shp_file_path = os.path.join(shp_folder, shp_file)\n",
    "    sql_file_path = os.path.join(shp_folder, \"output.sql\")\n",
    "    create_table = '-a'\n",
    "    if not table_exists(table_name, schema_name):\n",
    "        create_table = '-c'\n",
    "    cmd = f'shp2pgsql -s {srid} -D {create_table} {shp_file_path} {schema_name}.{table_name} > {sql_file_path}'\n",
    "    print(cmd)\n",
    "    subprocess.run(cmd, shell=True, check=True)\n",
    "    return sql_file_path\n",
    "\n",
    "\n",
    "def dataframe_to_postgres(df, schema, table_name):\n",
    "    conn = create_engine(\"postgresql://localhost/work\")\n",
    "    df[0:10].to_sql(table_name, schema=schema, con=conn, if_exists='replace', index=False)\n",
    "    connection = psycopg2.connect(\"postgresql://localhost/work\")\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(f\"truncate table {schema}.{table_name}\")\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    conn = psycopg2.connect(\"postgresql://localhost/work\")\n",
    "    cur = conn.cursor()\n",
    "    buffer = StringIO()\n",
    "    df.to_csv(buffer, index=False, header=False)\n",
    "    buffer.seek(0)\n",
    "    copy_query = f\"COPY {schema}.{table_name} FROM stdin WITH CSV\"\n",
    "    cur.copy_expert(copy_query, buffer)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "def get_column_names(data_set, columns, replace_concept=None):\n",
    "    column_names = []\n",
    "    for col in columns:\n",
    "        vd = get_variable_details(data_set, col)\n",
    "        col_name = col\n",
    "        if vd and col not in ['NAME']:\n",
    "            concept = vd['concept']\n",
    "            if replace_concept:\n",
    "                concept = replace_concept\n",
    "            col_name = re.sub(r\" FOR SELECTED [^\\(]*\", \" \", concept) + ' ' + vd['label']\n",
    "        col_name = re.sub(r\"[^a-z0-9]+\", \" \", col_name.lower()).strip().replace(\" \", \"_\")\n",
    "        col_name = col_name.replace(\"_estimate_total\", \"\")\n",
    "        column_names.append(col_name)\n",
    "    return column_names\n",
    "\n",
    "def census_data_to_db(table_name, column_names, data):\n",
    "    df = pd.DataFrame(data[1:], columns = column_names)\n",
    "    for col in df.columns:\n",
    "        if col not in ('name', 'state', 'place'):\n",
    "            df[col] = df[col].astype(float)\n",
    "    if 'place' in df.columns and 'state' in df.columns:\n",
    "        df[\"place_id\"] = df['state'] + df['place']\n",
    "        df[\"place_id\"] = df['place_id'].astype(int)\n",
    "    dataframe_to_postgres(df, \"census\", table_name)\n",
    "\n",
    "def get_geos(geo_type):\n",
    "    res = requests.get(f\"https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/{geo_type}/\")\n",
    "    for file_name in re.findall(r'href=\"([^.]+.zip)\"', res.text):\n",
    "        print(f\"Process: {file_name}\")\n",
    "        url = f\"https://www2.census.gov/geo/tiger/TIGER_RD18/LAYER/{geo_type}/{file_name}\"\n",
    "        downloaded_zip = download_file(url, '.downloaded')\n",
    "        try:\n",
    "            unzipped_folder = unzip_file(downloaded_zip, 'unzipped')\n",
    "        except:\n",
    "            print(f\"deleting bad file: {downloaded_zip}\")\n",
    "            os.remove(downloaded_zip)\n",
    "            continue\n",
    "        sql_file_path = shp2pgsql(\"census\", f\"geo_{geo_type.lower()}\", unzipped_folder, \"4326\")\n",
    "        print(f\"Load: {sql_file_path}\")\n",
    "        subprocess.run(f\"psql -d work -f {sql_file_path}\", shell=True, check=True, \n",
    "                       stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "        shutil.rmtree(unzipped_folder)\n",
    "\n",
    "\n",
    "def get_schools(table_name, data_id, from_srid):\n",
    "    downloaded_zip = download_file(f\"https://opendata.arcgis.com/api/v3/datasets/{data_id}/downloads/data?format=shp&spatialRefId={from_srid}&where=1%3D1\", 'downloaded')\n",
    "    if os.path.exists('.unzipped'):\n",
    "        shutil.rmtree(unzipped_folder)\n",
    "    unzipped_folder = unzip_file(downloaded_zip, '.unzipped')\n",
    "    sql_file_path = shp2pgsql(\"schools\", table_name, unzipped_folder, \"{from_srid}:4326\")\n",
    "    print(f\"Load: {sql_file_path}\")\n",
    "    subprocess.run(f\"psql -d work -f {sql_file_path}\", shell=True, check=True, \n",
    "                   stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "    shutil.rmtree(unzipped_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57cab2f-9266-41a2-a339-ee45f827e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df_to_table(df, schema, table_name):\n",
    "    conn = psycopg2.connect(CONN_STR)\n",
    "    cur = conn.cursor()\n",
    "    buffer = StringIO()\n",
    "    df.to_csv(buffer, index=False, header=False)\n",
    "    buffer.seek(0)\n",
    "    copy_query = f\"COPY {schema}.{table_name} FROM stdin WITH CSV\"\n",
    "    cur.copy_expert(copy_query, buffer)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "def get_census_data(data_set, variables, geo):\n",
    "    for st in get_states():\n",
    "        print(f\"Process state: {st['name']}\")\n",
    "        data_names = variables.split(\",\")\n",
    "        ENDPOINT = f\"{BASE_URL}/{data_set}?get=NAME,{variables}&for={geo}:*&in=state:{st['statefp']}&key={CENSUS_API_KEY}\"\n",
    "        response = requests.get(ENDPOINT)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "        else:\n",
    "            print(f\"Error {response.status_code}: {response.text}\")\n",
    "            return None\n",
    "        df = pd.DataFrame(data[1:], columns = data[0])\n",
    "        for col_num, col in enumerate(df.columns):\n",
    "            if col_num >= 1 and col_num <= len(data_names):\n",
    "                df[col] = df[col].astype(float)\n",
    "        geo_id_cols = df.columns[len(data_names)+1:len(df.columns)]\n",
    "        df[\"geo_id\"] = df[geo_id_cols].astype(str).apply(''.join, axis=1)\n",
    "        for col in data_names:\n",
    "            df[\"metric_id\"] = get_or_insert_metric(data_set, col)\n",
    "            new_df = df[[\"geo_id\", \"metric_id\", col]].copy()\n",
    "            append_df_to_table(new_df, \"census\", \"metric_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d6b3f-428b-4443-a50a-042a2e76aed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_geos(\"TRACT\")\n",
    "get_geos(\"STATE\")\n",
    "get_geos(\"COUNTY\")\n",
    "get_geos(\"PLACE\")\n",
    "get_geos(\"BG\")\n",
    "get_geos(\"TABBLOCK20\") # takes a few hours to download all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba22a8b-8027-40cc-a5fb-e670c788ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_schools(\"public_school\", \"87376bdb0cb3490cbda39935626f6604_0\", \"3857\")\n",
    "get_schools(\"private_school\", \"0dfe37d2a68545a699b999804354dacf_0\", \"4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac9dbc0-e4ba-48d0-894e-9f6100b5ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# population by age, sex male\n",
    "fields = ','.join(['P12_0{:0>2}N'.format(d) for d in range(1, 26)])\n",
    "data = get_census_data('2020/dec/dhc', fields, 'place')\n",
    "\n",
    "# population by age, sex female\n",
    "fields = ','.join(['P12_0{:0>2}N'.format(d) for d in range(26, 50)])\n",
    "data = get_census_data('2020/dec/dhc', fields, 'place')\n",
    "\n",
    "# population by age, sex male, white only\n",
    "fields = ','.join(['P12I_0{:0>2}N'.format(d) for d in range(1, 26)])\n",
    "data = get_census_data('2020/dec/dhc', fields, 'place')\n",
    "\n",
    "# population by age, sex female, white only\n",
    "fields = ','.join(['P12I_0{:0>2}N'.format(d) for d in range(26, 50)])\n",
    "data = get_census_data('2020/dec/dhc', fields, 'place')\n",
    "\n",
    "# income data\n",
    "fields = ','.join(['B19001_0{:0>2}E'.format(d) for d in range(1, 18)])\n",
    "data = get_census_data('2021/acs/acs5', fields, 'place')\n",
    "\n",
    "# education\n",
    "fields = ','.join(['B29002_0{:0>2}E'.format(d) for d in range(1, 9)])\n",
    "data = get_census_data('2021/acs/acs5', fields, 'place')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d976169-108f-482b-b542-0744f9b05492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tracts population by sex and age\n",
    "fields = ','.join(['P12_0{:0>2}N'.format(d) for d in range(1, 26)])\n",
    "data = get_census_data('2020/dec/dhc', fields, 'tract')\n",
    "\n",
    "fields = ','.join(['P12_0{:0>2}N'.format(d) for d in range(26, 50)])\n",
    "data = get_census_data('2020/dec/dhc', fields, 'tract')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "65fd02a8-881b-4544-a2ac-344586024a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process state: Alabama\n",
      "Process state: Alaska\n",
      "Process state: Arizona\n",
      "Process state: Arkansas\n",
      "Process state: California\n",
      "Process state: Colorado\n",
      "Process state: Connecticut\n",
      "Process state: Delaware\n",
      "Process state: District of Columbia\n",
      "Process state: Florida\n",
      "Process state: Georgia\n",
      "Process state: Hawaii\n",
      "Process state: Idaho\n",
      "Process state: Illinois\n",
      "Process state: Indiana\n",
      "Process state: Iowa\n",
      "Process state: Kansas\n",
      "Process state: Kentucky\n",
      "Process state: Louisiana\n",
      "Process state: Maine\n",
      "Process state: Maryland\n",
      "Process state: Massachusetts\n",
      "Process state: Michigan\n",
      "Process state: Minnesota\n",
      "Process state: Mississippi\n",
      "Process state: Missouri\n",
      "Process state: Montana\n",
      "Process state: Nebraska\n",
      "Process state: Nevada\n",
      "Process state: New Hampshire\n",
      "Process state: New Jersey\n",
      "Process state: New Mexico\n",
      "Process state: New York\n",
      "Process state: North Carolina\n",
      "Process state: North Dakota\n",
      "Process state: Ohio\n",
      "Process state: Oklahoma\n",
      "Process state: Oregon\n",
      "Process state: Pennsylvania\n",
      "Process state: Rhode Island\n",
      "Process state: South Carolina\n",
      "Process state: South Dakota\n",
      "Process state: Tennessee\n",
      "Process state: Texas\n",
      "Process state: Utah\n",
      "Process state: Vermont\n",
      "Process state: Virginia\n",
      "Process state: Washington\n",
      "Process state: West Virginia\n",
      "Process state: Wisconsin\n",
      "Process state: Wyoming\n",
      "Process state: American Samoa\n",
      "Error 204: \n"
     ]
    }
   ],
   "source": [
    "data = get_census_data('2020/dec/dhc', ','.join(['H10_001N', 'H10_002N', 'H10_010N']), 'place')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e44632e-13c4-4227-86cb-68372e0ba1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
